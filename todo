Symptom: for all images, layer 2 activates the exact same neurons every time. 
DONE
- start server devbox
- put random static in, see what comes out for layer 2 and layer 20
- do analysis on one that is more in the middle
- put an image in, see what comes out for both layers
- see what "read image" does
- read hugofry's code, does it calculate MSE before or after preprocessing? (not relevant, MSE is from activations so way after processing anyway)


1.
- established: the way images are passed in has a huge impact on the latents which come out. This means we should probably re-train
- check what exact format the tensors coming out of streaming tensor dataset come out in

2. 
- check what our prior training run was doing "load_image" strategy

3.
- test if to_tensor has any impact --> it does. Instead we want to use frombuffer to load the raw bytes then decode_jpeg

4. 
- update tardataset so it spits out correct tensors


5. 

TODO NOW
- test multi worker loading of dataset
- start generating alternate dataset of activations
    - re-build and push docker image
    - repopulate queue


TODO GENERAL
- do a test run of retraining, compare to existing, see if it's getting better results
- read what people usually do with vision SAEs
- 