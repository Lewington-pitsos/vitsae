---------------------------------------------- 15/10/2024
1. 

2. 

3. 

- refactor training script

4. 

- unit test saving/reloading


5. 

TODO NOW
- get prefect saving/reloading
   - run actual online test of saving/loading



PREFLIGHT:
- make sure we pass in an id, instead of name

TODO GENERAL
- download some activations, confirm they differ
- do a test run of retraining, compare to existing, see if it's getting better results
- look at position MSE
- calculate the mean feature latent across the image and use this for classification
- clean up that bullshit on s3


---------------------------------------------- 14/10/2024


Symptom: for all images, layer 2 activates the exact same neurons every time. 
DONE
- start server devbox
- put random static in, see what comes out for layer 2 and layer 20
- do analysis on one that is more in the middle
- put an image in, see what comes out for both layers
- see what "read image" does
- read hugofry's code, does it calculate MSE before or after preprocessing? (not relevant, MSE is from activations so way after processing anyway)


1.
- established: the way images are passed in has a huge impact on the latents which come out. This means we should probably re-train
- check what exact format the tensors coming out of streaming tensor dataset come out in

2. 
- check what our prior training run was doing "load_image" strategy

3.
- test if to_tensor has any impact --> it does. Instead we want to use frombuffer to load the raw bytes then decode_jpeg

4. 
- update tardataset so it spits out correct tensors


5. 
- test multi worker loading of dataset
- start generating alternate dataset of activations
- sonja joseph's vit primsa isn't really related to SAEs
- repopulate queue


6. 
- make tardataset compatible with collate fn

7. 

8. 
- read imagenet curve detector https://arxiv.org/pdf/2406.03662
- get dataloader working without tensors
- test new image based tardataset
- start generating alternate dataset of activations
