Symptom: for all images, layer 2 activates the exact same neurons every time. 
DONE
- start server devbox
- put random static in, see what comes out for layer 2 and layer 20
- do analysis on one that is more in the middle
- put an image in, see what comes out for both layers
- see what "read image" does
- read hugofry's code, does it calculate MSE before or after preprocessing? (not relevant, MSE is from activations so way after processing anyway)


1.
- established: the way images are passed in has a huge impact on the latents which come out. This means we should probably re-train
- check what exact format the tensors coming out of streaming tensor dataset come out in

2. 
- check what our prior training run was doing "load_image" strategy


TODO NOW
- update tardataset so it spits out images
- read what people usually do with vision SAEs



TODO GENERAL
- do a test run of retraining, compare to existing, see if it's getting better results